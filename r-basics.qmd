---
title: "&nbsp;"
engine: knitr
filters:
  - webr
---
# QSURE Coding Workshop 2025{background-color="#007CBA" style="text-align: center;"}

[Part 1: R Basics]{.larger}

<br> 

Karissa Whiting <br>
June 10th, 2025


<p align="center"><img src="images/core_hex_stickers.png"width=20%></p>


```{r}
#| echo: false
#| results: false
#| cache: false
#| 
set.seed(20230515)
 
knitr::opts_chunk$set(echo = TRUE, results = 'asis')

library(tidyverse)
library(gtsummary)
library(genieBPC)
library(gt)
library(gnomeR)



```


# Purpose of Coding Workshop

Provide you tools & resources to get properly set up to conduct impactful and reproducible research during your time at MSK (and after!)

<br>

- **Beginners:** Introduce you to general coding concepts and basics of the R programming language 

- **Intermediate/Advanced Coders:** Fill potential gaps in your R knowledge and introduce packages useful for common statistical analyses and reporting.

- **All:** Learn to build reproducible code bases (of any language) from the ground up. 


::: {.notes}

- While other seminars are likely more lecture style, these workshops are meant to be a hand-on intro to coding for statistical analysis projects. 

...

- All/reproducible- project organizaiton, file managements, ersion control, documentations, etc. 


:::



# Workshop Agenda

- **Lesson 1** â€“ 6/10/2024
    - Overview of Coding Concepts
    - R Basics (Quick Review)
- **Lesson 2** - 6/12/2024
    - Guided Example
        - Project Setup & Reproducibility 
        - Data Cleaning
        - Analyzing/Modeling the Data
        - Reporting Your Results
- **Lesson 3** - TBD

::: {.notes}

- Short review on basic R vocab 

- Skip dplyr basics but include some advanced dplyr/data cleaning 

- Interactive Code-along. Focus on project setup, statistical analyses

- Optional 3rd session on R package making/Github

:::



# R, Rstudio, Open source philosophy

- **R** is an object-oriented **open-source** programming language used mostly for statistical computing and graphics. Despite being OOO, R can be written in a functional style. 

- **Open source** means the original source code is freely available, and can be distributed and modified. Also, users can contribute to the usefulness by creating packages, which implement specialized functions for all kinds of uses (e.g. statistical methods, graphical capabilities, reporting tools). 
Added Bonus: vibrant R community!

- **RStudio** is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting code editor that supports direct code execution, as well as tools for plotting, history, debugging and work space management.

# 

<center>
<img src="images/r-cars.jpg" width="100%"/>
</center>


# Python

- **Python** is a versatile programming language used widely in data science, web development, automation, and statistics. Unlike R, it was created as a general purpose language but has evolved significantly. 

- Python is also **Open source** (PyPI - Python Package Index)

- Some popular IDEs include **VS Code**, **JupyterLab**, **Positron** and more



# R vs. Python

[Which is better?]{.larger}

<center>
<img src="images/rvspy.gif" width="100%"/>
</center>

# R vs. Python

[They're both great!]{.larger}

<center>
<img src="images/randpy.png" width="100%"/>
</center>

::: {.notes}

- R has a longer history as a statistical language versus a general programming language, so it's useful as a statistician to learn some R as some more niche methods may not be available in Python

:::
 
# R Basics {background-color="#007CBA" style="text-align: center;"}


::: {.notes}

- Please open Rstudio, and start a new R file 

:::
 
# General Things

- `<-` is the assignment operator (`=` also works)

```{webr-r}
v1 <- c(1, 2, 3)
v1
```

- R is case sensitive, bE cArEfUl!

```{webr-r}
x <- "Apple"
y <- "apple"
x == y
```

- `?` is your friend if you want to look at documentation! (e.g. type `?mean()` in the console)

```{webr-r}
?mean
```


# A Note About The Pipe Operator

- The `%>%` (pipe) is a useful way to link functions together to make your code more succinct and easier to read.

- `|>` (base pipe) is another way to pipe operations 

```{webr-r}
#| eval: false
library(dplyr)

1:5 |> sum()

mtcars %>% 
    select(mpg) %>% 
    filter(mpg == max(mpg))

```


# Data Types

R basic data types: 

* logical (`TRUE`)
* integer (`1`)
* numeric (a.k.a. double) (`1.2`)
* character (`"Purple"`)
* factor ("a")
* complex (nobody ever uses these really)

# Beware Data Type Coercion

What is the most flexible data type?

```{webr-r}
#| echo: true
x <- c("apple", 3)


```

# Beware Data Type Coercion

- Since columns of a data.frame must be of the same type, some data may be coerced in unexpected ways when reading in a csv or excel file. 

- character is often the default for mixed data types


```{webr-r}
#| echo: true
#| 
y <- c(3, 2, "twenty") 
y
```

```{webr-r}
#| echo: true
#| error: true
sum(y)

```



# How Data is Stored 

R has 5 basic data structures: 

:::: {.columns}

::: {.column width="50%"}

1. vector
2. matrix
3. array
4. list
5. data.frame/tibble

::: 


::: {.column width="50%"}

:::

::::

# How Data is Stored

::: {.columns}

::: {.column width="50%"}

1. vector

:::

::: {.column width="50%"}

- only 1 data type allowed

```{r }

# character
c("apple", "orange")

# numeric
c(1:15)
```

:::

:::

# How Data is Stored

:::: {.columns}

::: {.column width="50%"}

1. vector
2. **matrix**

:::

::: {.column width="50%"}


2d, only 1 data type allowed

```{r }
#| results: markup
#| 
letters <- c("a","b","c","d", "e", "f")
matrix(letters, nrow=2, ncol=3)
```

:::

::::




# How Data is Stored

:::: {.columns}

::: {.column width="50%"}

1. vector
2. matrix
3. **array**

:::


::: {.column width="50%"}

- n-dimensions, of 1 data type

```{r }
#| results: markup
#| 
# Create two vectors of different lengths.
vector1 <- c(5,9,3)
vector2 <- c(10,11,12,13,14,15)

array(c(vector1,vector2),dim = c(3,3,2))
```

:::

::::



# How Data is Stored 


:::: {.columns}

::: {.column width="50%"}

1. vector
2. matrix
3. array
4. **list**

:::

::: {.column width="50%"}


- any data type allowed

```{r }
#| results: markup
#| 
my_list <- list("a", 2, TRUE) 
str(my_list)
```

:::

::::



# How Data is Stored

:::: {.columns}

::: {.column width="50%"}

1. vector
2. matrix
3. array
4. list
5. **data.frame/tibble**

:::


::: {.column width="50%"}

    - any data type is allowed, but each column has to have the same type
    - the most important for data analysts. Most similar to an excel spreadsheet/statistical data file

```{r }
#| results: markup

head(iris, 4)
```

:::

::::


# The R Analysis Workflow {background-color="#007CBA" style="text-align: center;"}


# The Analysis Workflow

[Steps of a basic data analysis project:]{.larger}

::: {.incremental .larger}

[1. Setup Your Project]{.emphasized}

[2. Clean and Explore Data]{.emphasized}
    
[3. Analyze Data]{.emphasized}
    
[4. Report Your Findings]{.emphasized}
 
[5. Iterate, Share, and Collaborate!]{.emphasized}

:::
    
# Analysis Workflow Tools (R)

[1. Setup Your Project]{.emphasized}

    - `here`, `renv`

[2. Clean and Explore Data]{.emphasized}

    - `tidyverse`
  
[3. Analyze Data]{.emphasized}

    - `stats`
    - `survival`, `lme4`, `glmnet`
    - `ggplot2` 
    
[4. Report Your Findings]{.emphasized}

    - R Markdown / Quarto
    - `gt` / `gtsummary`
    
[5. Iterate, Share, and Collaborate!]{.emphasized}

    - git / GitHub
    

# Analysis Workflow Tools (Python)

[1. Setup Your Project]{.emphasized}
  
    - `venv`, `conda`
    
[2. Clean and Explore Data]{.emphasized}

    - `pandas` / `numpy`

[3. Analyze Data]{.emphasized}

    - `scipy.stats`, `statsmodels`, `scikit-learn`
    - `seaborn`, `matplotlib`

[4. Report Your Findings]{.emphasized}

    - Jupyter / Quarto

[5. Iterate, Share, and Collaborate!]{.emphasized}

    - git / GitHub


# The Analysis Workflow

[Steps of a basic data analysis project:]{.larger}


[1. Setup Your Project]{.emphasized}

2. Clean and Explore Data
    
3. Analyze Data
    
4. Report Your Findings
 
5. Iterate, Share, and Collaborate!



# Anatomy of a Project


:::: {.columns}

::: {.column width="40%"}

<p align="center"><img src="images/project-folders.png"width=100%></p>

:::


::: {.column width="60%"}

- keep raw and processed data separate (`raw-data`, vs. `data`)

- folder for `scripts` ordered or labelled descriptively
- optionally can have `admin` for project notes, etc  and `outputs` for final reports and figures 

- **README** - text file that introduces and explains a project (`usethis::use_readme_md()`)
- **R Project (.Rproj file) ** - tells RStudio all your files belong to one project and sets working directory for entire project. 

:::

::::


# Your Turn: Setup Your Project


1. Create a new folder on your computer and name it "your-initials-case-study-2025"

2. Create subfolders within your project folder called: `admin`, `raw-data`, `scripts`, `data`, `outputs`

3. Create a new R Project in Rstudio from this folder (**File > New Project > Existing Directory**)

4. Create a `README.md` using `usethis::use_readme_md()`

5. Open a new R file (**RStudio > New File > R Script**) to use as a scratch file

# The Analysis Workflow

<br>

[Steps of a basic data analysis project:]{.larger}

1. Setup Your Project

[2. Clean and Explore Data]{.emphasized}
    
3. Analyze Data
    
4. Report Your Findings
 
5. Iterate, Share, and Collaborate!


# Exploring Your Data

- `colnames()` - will give you the column names
- `ncol()` and `nrow()` - will give you the total count of columns and rows respectively
- `class()`, `str()`, `attributes()` will give you meta-information on the object 
- `head()`, `tail()` show the top or bottom rows of your df
- `View()` will show the whole dataframe 
- `table()` will summarise variables

```{webr-r}

str(iris)
nrow(iris)
```



# Exploring Your Data

```{webr-r}

colnames(iris)
class(iris)
head(iris, 3)
table(iris$Species)

```


# Cleaning Data: Intro to tidyverse

The tidyverse package is a collection of R packages designed for data analysis, all of which share a similar design, grammar, and structure.

```{r }
#| results: markup
# load it
library(tidyverse)

# check out the cute logo
tidyverse_logo()

```


# Cleaning Data: Intro to tidyverse

- **readr**: data import/export
- **tibble**: easier to work with data frames
- **dplyr**: data manipulation
- **tidyr**: data manipulation
- **ggplot2**: graphics and visualization
- **purrr**: functional programming toolkit, replaces the need for many loops
- **stringr**: string manipulation
- **forcats**: re-imagined factor data types

There are several additional packages which are installed as part of the tidyverse, but are not loaded by default.



# The tidyverse style

- Overall the tidyverse style emphasizes code readability and intuitive coding 

- Human-readable syntax and pipe-based workflows

- Shortcuts for common data manipulation tasks

- tidyverse has been developed and significantly improved in the last few years, with a lot of ongoing work being done to further increase usability.


# Cleaning Data: dplyr

The dplyr package is a data manipulation and cleaning package. A few of the key functions (verbs) in dplyr are:

- select()
- mutate()
- filter()
- arrange()
- group_by()
- summarize()

All take a data frame as input, and return a data frame as output.

**We will briefly review during case study**

# The Analysis Workflow

[Steps of a basic data analysis project:]{.larger}

1. Setup Your Project

2. Clean and Explore Data
    
[3. Analyze Data]{.emphasized}
    
4. Report Your Findings
 
5. Iterate, Share, and Collaborate!


# Statistical Models


We will cover:

- linear model

- logistic model

- survival analyses 

- and more....(depending on what's useful for you!)


# Formula Syntax 

- Code for models and stats tests often require formula syntax
- In general `~` is used to separate your outcome on the left hand side and your predictors on the right hand side
- Your outcome will always be on the left side of the `~`
- Only some univariate tests like `chisq.test()` do not use the `~` notation 
- The `stats` package is already loaded in R which will make it easier to use common statistical tests
- General notation: `model(outcome ~ covariates, data)`


# Example of linear model


- Continuous outcome 
- Specifying interactions 

```{r }
#| eval: true

mtcars$vs  <- as.character(mtcars$vs)
mtcars$cyl   <- as.character(mtcars$cyl)
mod1 <- lm(mpg ~ vs * cyl, data = mtcars)
class(mod1) # class of lm which is a list

names(mod1)

```


# Example cont.

```{r }
#| results: markup
#| 
summary(mod1)

```


# Check Model Diagnostics

- All models have different underlying assumptions (e.g. normality of residuals). Consider these when choosing a model and check them when model fitting. 
- Check multicollinearity among your variables and how your models handles it:

```{webr-r}
#| message: false

mod1 <- lm(Sepal.Length ~ Sepal.Width + Species, data = iris)

vifmod <- car::vif(mod1) #will not work with interaction present
vifmod
```

# Check Model Diagnostics

- Check outliers and influential points (e.g. Cook's Distance- a measure of how influential a data point is in a regression analysis). 

```{webr-r}

#influencers 
cutoff <- 4/((nrow(mtcars)-length(mod1$coefficients)-2)) 


```

(If the Cook's Distance of a data point exceeds this cutoff, that data point might be considered unusually influential)

# Check model diagnositcs

```{r }
#many options for which! 
plot(mod1, which=1, cook.levels=cutoff)

```



# Example cont.

```{r }
#| results: markup
#| 
summary(mod1)

```

- while it is nice to see the summary results, you wouldn't present them in this fashion



# Report Your Findings


- `broom` and `gt`/`gtsummary` will help
- `broom` is a package that helps tidy model results into data.frames
- this helps with reporting and you can further format the data.frame and present with `gt`

```{r }
#| message: false

moddf <- broom::tidy(mod1) %>% #didn't load broom just called one function 
          mutate(p.value = round(p.value,3)) %>% 
          select(-std.error)

gt::gt(moddf)

```



# gtsummary

- `gtsummary` makes it easier to report model and descriptive statistics (more on this in the example)
- For more helpful examples: https://www.danieldsjoberg.com/gtsummary/index.html 


# gtsummary

```{r }
tbl_regression(mod1)
```



# Customizing gtsummary

```{r }

library(labelled)

var_label(mtcars$cyl) <- "Cylinder"

newmodsum <- lm(mpg ~ vs * cyl, data = mtcars) %>% 
  tbl_regression() %>% 
      bold_labels() %>% 
      modify_caption("New title for model")


```


# Customizing gtsummary

```{r }

newmodsum

```


# Logistic models


- binary outcome (0/1)
- R will model the '1' as the event by default make sure your variable is coded correctly

```{r }
mtcars$vs <- as.numeric(mtcars$vs)
mtcars$am <- as.character(mtcars$am)

mod2 <- glm(vs ~ am , data = mtcars, family =  "binomial")



```



# Summarize logistic model

```{r }

tbl_regression(mod2, exponentiate = TRUE) %>% 
    bold_labels()

```



# Survival analysis

- Outcome is both time and an event (e.g death, progression)
- Have to specify both in the left side of model formula
- Dr. Emily Zabor put together great materials for survival analysis here: 
    - [https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html)

<p align="center"><img src="images/surv.png"width=50%></p>


# Survival analysis

```{r }
library(survival)

lung <- lung %>% 
        mutate(ph.ecog = as.character(ph.ecog),
               sex = as.character(sex))

mod3 <- coxph(Surv(time, status)~ph.ecog+sex,data = lung)
mod4 <- survfit(Surv(time, status) ~ sex,data = lung)


```



# Survival analysis

```{r }

tbl_regression(mod3, exponentiate = TRUE)

```


# Survival analysis: Model Assumptions

- test proportional hazards

```{r }
#| results: markup
#| 
cox.zph(mod3)

```


# Tomorrow: Coding Exercise 

- Case Study: Diabetes Risk Factors

- Github Repo With Case Study: [https://github.com/karissawhiting/qsure-case-study](https://github.com/karissawhiting/qsure-case-study)

- Check out script > `01_clean_data.R`

# Thank You!




